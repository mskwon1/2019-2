# 기계학습이란

## 정의

- 학습
  - 경험의 결과로 나타나는, 비교적 지속적인 행동의 변화나 그 잠재력의 변화 또는 지식을 습득하는 과정
- 기계학습
  - 사무엘(인공지능 초창기), 컴퓨터가 **경험을 통해 학습**할 수 있도록 프로그래밍할 수 있다면, 세세하게 프로그래밍해야하는 번거로움에서 벗어날 수 있다

### 현대적 정의

- 어떤 컴퓨터그램이 T라는 작업을 수행할 때, 
  경험을 통해 성능이 개선된다면 이 프로그램은 학습을 한다고 말할 수 있음
  - **최적의 알고리즘**을 찾는 행위
    - 경험 **E**를 통해, 주어진 작업 **T**에 대한 성능 **P**의 향상
- 사례 데이터, 즉 과거 경험을 이용하여 성능 기준을 최적화하도록 프로그래밍 하는 작업
- 성능을 개선하거나 정확하게 **예측**하기 위해 경험을 이용하는 계산학 방법들

### 기계학습 VS 전통적인 프로그래밍

![1567587767730](../../typora_images/1567587767730.png)

## 지식기반 :arrow_forward: 기계학습 대전환

- 인공지능의 탄생
  - 컴퓨터의 뛰어난 능력
    - 사람이 어려워하는 일을 아주 쉽게 수행한다
  - 컴퓨터에 대한 기대감
    - 사람이 쉽게하는 일도 컴퓨터가 할 수 있지 않을까?
    - **1950년대에 '인공지능' 개념 첫 등장**
- 초창기 : 지식기반 방식
  - **경험적인 지식** 혹은 **사실**을 인위적으로 컴퓨터에 부여하여 학습
- 큰 깨달음
  - **지식기반의 한계**
  - 사람은 변화가 심한 장면을 아주 쉽게 인식하지만, **왜 그렇게 인식**하는지 서술하지는 못함
- 주도권 전환
  - 지식 기반 :arrow_forward: 기계학습
  - 데이터 중심 접근방식

## 개념

![1567567945435](../../typora_images/1567567945435.png)

- 교사학습의 예

  - 가로축은 **시간**, 세로축은 **이동체**의 위치
  - 관측한 4개의 점이 데이터

- 예측 문제

  - 임의의 시간이 주어질 때, **이동체의 위치**는?
  - 회귀문제와 분류문제
    - 회귀 : 목표치가 **실수**
    - 분류 : 목표치가 **부류 혹은 종류의 값**

- 훈련집합

  - 가로축은 특징, 세로축은 목표치 
  - 관측한 4개의 점이 **훈련집합**

  ![1567568096743](../../typora_images/1567568096743.png)

- 관찰된 데이터를 어떻게 설명할 것인가?

  - 눈대중으로 봤을 때 점들이 직선을 이룬다 :arrow_forward: 모델로 **직선을 선택을 가정**
  - 직선 모델의 수식
    - **y = wx + b (매개변수 w, b)**

- 기계학습은

  - 가장 정확하게 예측할 수 있는 **최적의 매개변수**를 찾는 작업
  - 처음에는 최적값을 모르니 **임의의 값**에서 시작, 점점 성능을 개선해 **최적에 도달**

  ![1567568377185](../../typora_images/1567568377185.png)

  - f1 :arrow_forward: f2 :arrow_forward: f3 (**성능개선**)
    - w = 0.5, b = 2

- 학습을 마치면

  - 새로운 **특징(x값)**에 대응되는 **목표치(y값)**의 **예측에 사용**
  - y = 0.5x + 2 :arrow_forward: x가 10일때 y가 7이라고 **예측**

- 궁극적인 목표

  - 훈련집합에 없는 **새로운 샘플**에 대한 **오류 최소화**
    - 새로움 샘플 집합 = 테스트 집합(**Test Set**)
  - **일반화 능력** : 테스트 집합에 대한 높은 성능

- 필수요소

  - 내, 외부적 **규칙 존재**
  - **수학적으로 설명 불가능**
  - **데이터**가 있어야 함

## 사람 VS 기계 학습

![1567569243469](../../typora_images/1567569243469.png)

# 특징공간에 대한 이해

## 1차원과 2차원 특징공간

- 1차원 특징공간

  ![1567569326772](../../typora_images/1567569326772.png)

- 2차원 특징공간

  ![1567569343602](../../typora_images/1567569343602.png)

  - 특징 **벡터 표기**

    ![1567569400810](../../typora_images/1567569400810.png)

  - 예시

    - x = (몸무게,키)^T, y = 장타율

## 다차원 특징공간

![1567569452626](../../typora_images/1567569452626.png)

- x값(특징)의 종류가 **몇개인지에 따라 d차원**
  - 모든 데이터는 **특징공간 안에 존재**한다

- d-차원 데이터

  - 특징 벡터 표기

    ![1567569680784](../../typora_images/1567569680784.png)

  - 학습모델

    - 직선 모델인 경우 : 매개변수 수 = **d+1**

      ![1567569727681](../../typora_images/1567569727681.png)

    - 2차 곡선 모델인 경우 : 매개변수 수 = **d^2 + d + 1**

      ![1567569798325](../../typora_images/1567569798325.png)

      - **최적화를 잘 해야 함**

## 특징공간 변환과 표현문제

- 선형 분리 불가능한 원래 특징 공간

  - 직선모델 적용시 **정확도 75프로 한계**

    ![1567569893113](../../typora_images/1567569893113.png)

    - XOR 문제
    - **좌표계를 변형시켜** 선형에 가깝게 만든다

- 표현문제의 예

  ![1567569961228](../../typora_images/1567569961228.png)

- 식으로 변환된 새로운 특징 공간

  - **공간변환**을 통해 직선 모델로 **100% 정확도**

    ![1567570131274](../../typora_images/1567570131274.png)

- 표현학습

  - 좋은 **특징 공간을 자동으로 찾는 작업**

  - 딥 러닝 (Deep Learning)

    - 다수의 은닉층을 가진 **신경망을 이용하여 최적의 계층적인 특징 공간을 찾아냄**
    - 아래쪽 은닉층은 **저급 특징**(선, 구석점 등), 위쪽은 **고급 특징**(얼굴, 바퀴 등) 추출

    ![1567570244793](../../typora_images/1567570244793.png)



- 차원에 대한 몇가지 설명
  - 거리 : **차원에 무관하게 수식 적용 가능**
  - 보통 2~3차원의 **저차원에서 식을 고안해 고차원으로 확장 적용**
- **차원의 저주**(Curse of dimensionality)
  - 차원이 높아짐에 따라 발생하는 현실적인 문제들
    - 차원이 크면 클수록 **데이터가 더 많이 필요**하다

