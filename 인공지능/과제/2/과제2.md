#### 4.

컨볼루션 층의 입력 크기가 $32*32*3$이고

- (a) 10개 $5*5$ 필터들을 보폭 1과 덧대기 2로 적용하였을 때 출력의 크기와 매개변수의 수를 구하세요

  출력의 크기 = $W2 * H2 * D2$

  ​	$W2 = (W1-F+2P)/S + 1 = (32 - 5 + 4)/1 + 1 = 32$

  ​	$H2 = (H1 - F + 2P)/S + 1 = (32-5+4)/1 + 1 = 32$

  ​	$D2 = K = 10$

  ​	따라서, 출력의 크기 = $32 * 32 * 10$ 

  매개변수의 수 = $(F*F*D1)K + K = (5*5*3)10 + 10 = 760$ 

- (b) 동일한 입력에 64개 3*3 필터들을 보폭 1과 덧대기 1로 적용하였을 때 출력의 크기와 매개변수의 수

  출력의 크기 = $W2 * H2 * D2$

  ​	$W2 = (W1-F+2P)/S + 1 = (32 - 3 + 2)/1 + 1 = 32$

  ​	$H2 = (H1 - F + 2P)/S + 1 = (32-3+2)/1 + 1 = 32$

  ​	$D2 = K = 64$

  ​	따라서, 출력의 크기 = $32 * 32 * 64$ 

  매개변수의 수 = $(F*F*D1)K + K = (3*3*3)64 + 64 = 1792$ 

#### 5.

다음 조건을 만족하는 컨볼루션 신경망을 구현하고, 3번의 (3), (6), (7)의 성능결과를 확인하고 비교하세요

- (1) INPUT - CONV(32 3\*3) - CONV(32 3\*3) - RELU - POOL - CONV(32 3\*3) - CONV(32 3\*3) - RELU - POOL 	- FC - OUTPUT
- (2) 3번 문제의 신경망에 Adam 최적화 (강의자료의 기본 hyper-parameters 사용) 적용
- (3) 데이터 확대 방법들 중 하나를 적용한 후, 3번 문제의 신경망 학습 (Hint : transforms)
- (4) 3번 문제의 신경망에 CONV 층마다 배치 정규화를 적용 (Hint : nn.BatchNorm)
- (5) 3번 문제의 신경망에 로그우도 (-log) 손실함수를 적용
- (6) 3번 문제의 신경망에 L2놈 규제 적용

#### 6. 

신경망의 출력이 $(0.4,2.0,0.001,0.32)^T$일 때 소프트맥스 함수를 적용한 결과를 쓰시오

- $(0.1325, 0.6563, 0.0889, 0.1223)^T$ (소수점 넷째자리로 반올림)

#### 7.

소프트맥스 함수를 적용한 후 출력이 $(0.001,0.9,0.001,0.098)^T$이고 레이블 정보가 $(0,0,0,1)^T$일때, 세 가지 목적함수, 평균제곱 오차, 교차 엔트로피, 로그우도를 계산하시오

- 평균제곱오차

  $e = \frac{1}{n}\sum^n_{i=1}(y_i - t_i)^2$

  $= \frac{1}{4}((0.001-0)^2 + (0.9-0)^2 + (0.001 - 0)^2 + (0.098 - 1)^2)$

  $= 0.4059$ (소수점 넷째자리로 반올림)

- 교차 엔트로피

  $e = -\sum_{i=1}^n(y_ilog_2o_i + (1-y_i)log_2(1-o_i))$

  $=-(log_2(1-0.001)+log_2(1-0.9) +log_2(1-0.001)+log_2(0.098))$

  $= 6.6759$ (소수점 넷째자리로 반올림)

- 로그우도

  $e= -log_2o_y$

  $= -log_2(0.098)$

  $= 3.3511$ (소수점 넷째자리로 반올림)